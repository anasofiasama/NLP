{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# URL Classifier by SVM"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Step 0: Importing librarys and packages**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 439,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Requirement already satisfied: pandas in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (1.4.3)\n",
                        "Requirement already satisfied: python-dateutil>=2.8.1 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from pandas) (2.8.2)\n",
                        "Requirement already satisfied: numpy>=1.18.5 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from pandas) (1.23.1)\n",
                        "Requirement already satisfied: pytz>=2020.1 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from pandas) (2022.1)\n",
                        "Requirement already satisfied: six>=1.5 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
                        "\n",
                        "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.2.1\u001b[0m\n",
                        "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
                        "Requirement already satisfied: regex in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (2022.7.25)\n",
                        "\n",
                        "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.2.1\u001b[0m\n",
                        "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
                        "\u001b[31mERROR: Could not find a version that satisfies the requirement re (from versions: none)\u001b[0m\u001b[31m\n",
                        "\u001b[0m\u001b[31mERROR: No matching distribution found for re\u001b[0m\u001b[31m\n",
                        "\u001b[0m\n",
                        "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.2.1\u001b[0m\n",
                        "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
                        "Requirement already satisfied: matplotlib in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (3.5.2)\n",
                        "Requirement already satisfied: pillow>=6.2.0 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from matplotlib) (9.2.0)\n",
                        "Requirement already satisfied: kiwisolver>=1.0.1 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from matplotlib) (1.4.4)\n",
                        "Requirement already satisfied: packaging>=20.0 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from matplotlib) (21.3)\n",
                        "Requirement already satisfied: fonttools>=4.22.0 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from matplotlib) (4.34.4)\n",
                        "Requirement already satisfied: pyparsing>=2.2.1 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from matplotlib) (3.0.9)\n",
                        "Requirement already satisfied: cycler>=0.10 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from matplotlib) (0.11.0)\n",
                        "Requirement already satisfied: python-dateutil>=2.7 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from matplotlib) (2.8.2)\n",
                        "Requirement already satisfied: numpy>=1.17 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from matplotlib) (1.23.1)\n",
                        "Requirement already satisfied: six>=1.5 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
                        "\n",
                        "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.2.1\u001b[0m\n",
                        "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
                        "Requirement already satisfied: nltk in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (3.7)\n",
                        "Requirement already satisfied: tqdm in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from nltk) (4.64.0)\n",
                        "Requirement already satisfied: click in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from nltk) (8.1.3)\n",
                        "Requirement already satisfied: joblib in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from nltk) (1.1.0)\n",
                        "Requirement already satisfied: regex>=2021.8.3 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from nltk) (2022.7.25)\n",
                        "\n",
                        "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.2.1\u001b[0m\n",
                        "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
                        "Requirement already satisfied: sklearn in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (0.0)\n",
                        "Requirement already satisfied: scikit-learn in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from sklearn) (1.1.1)\n",
                        "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from scikit-learn->sklearn) (3.1.0)\n",
                        "Requirement already satisfied: scipy>=1.3.2 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.9.0)\n",
                        "Requirement already satisfied: numpy>=1.17.3 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.23.1)\n",
                        "Requirement already satisfied: joblib>=1.0.0 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.1.0)\n",
                        "\n",
                        "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.2.1\u001b[0m\n",
                        "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
                        "Requirement already satisfied: wordsegment in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (1.3.1)\n",
                        "\n",
                        "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.2.1\u001b[0m\n",
                        "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
                    ]
                }
            ],
            "source": [
                "!pip install pandas\n",
                "!pip install regex\n",
                "!pip install re\n",
                "!pip install matplotlib\n",
                "!pip install nltk\n",
                "!pip install sklearn\n",
                "!pip install wordsegment"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 440,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[nltk_data] Downloading package stopwords to /home/gitpod/nltk_data...\n",
                        "[nltk_data]   Package stopwords is already up-to-date!\n"
                    ]
                }
            ],
            "source": [
                "import pandas as pd\n",
                "import regex as reg\n",
                "import re\n",
                "import matplotlib.pyplot as plt\n",
                "import unicodedata\n",
                "import nltk\n",
                "\n",
                "from sklearn.feature_extraction.text import CountVectorizer\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn import model_selection, svm\n",
                "from sklearn.naive_bayes import MultinomialNB\n",
                "from sklearn.metrics import classification_report, accuracy_score\n",
                "from nltk.corpus import stopwords\n",
                "nltk.download('stopwords')\n",
                "from wordsegment import load, segment"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Step 1 : Load the data**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 441,
            "metadata": {},
            "outputs": [],
            "source": [
                "url='https://raw.githubusercontent.com/4GeeksAcademy/NLP-project-tutorial/main/url_spam.csv'\n",
                "df_raw = pd.read_csv(url)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 442,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "<class 'pandas.core.frame.DataFrame'>\n",
                        "RangeIndex: 2999 entries, 0 to 2998\n",
                        "Data columns (total 2 columns):\n",
                        " #   Column   Non-Null Count  Dtype \n",
                        "---  ------   --------------  ----- \n",
                        " 0   url      2999 non-null   object\n",
                        " 1   is_spam  2999 non-null   bool  \n",
                        "dtypes: bool(1), object(1)\n",
                        "memory usage: 26.5+ KB\n"
                    ]
                }
            ],
            "source": [
                "df_raw.info()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 443,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>url</th>\n",
                            "      <th>is_spam</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>423</th>\n",
                            "      <td>https://flowingdata.com/2020/06/22/age-generat...</td>\n",
                            "      <td>False</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1443</th>\n",
                            "      <td>https://www.youtube.com/watch?v=7fHi3djOHl0</td>\n",
                            "      <td>False</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1787</th>\n",
                            "      <td>https://bitchesgottaeat.substack.com/</td>\n",
                            "      <td>False</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1967</th>\n",
                            "      <td>https://www.clarionledger.com/story/news/2020/...</td>\n",
                            "      <td>False</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2241</th>\n",
                            "      <td>https://www.morningbrew.com/daily/latest</td>\n",
                            "      <td>False</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1913</th>\n",
                            "      <td>https://benjaminreinhardt.com/wddw</td>\n",
                            "      <td>False</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2361</th>\n",
                            "      <td>https://deceuvel.nl/en/about/sustainable-techn...</td>\n",
                            "      <td>False</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1600</th>\n",
                            "      <td>https://www.morningbrew.com/daily/stories/2020...</td>\n",
                            "      <td>False</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1712</th>\n",
                            "      <td>https://www.ben-evans.com/newsletter</td>\n",
                            "      <td>True</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1562</th>\n",
                            "      <td>https://theconversation.com/northern-irelands-...</td>\n",
                            "      <td>False</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "                                                    url  is_spam\n",
                            "423   https://flowingdata.com/2020/06/22/age-generat...    False\n",
                            "1443        https://www.youtube.com/watch?v=7fHi3djOHl0    False\n",
                            "1787              https://bitchesgottaeat.substack.com/    False\n",
                            "1967  https://www.clarionledger.com/story/news/2020/...    False\n",
                            "2241           https://www.morningbrew.com/daily/latest    False\n",
                            "1913                 https://benjaminreinhardt.com/wddw    False\n",
                            "2361  https://deceuvel.nl/en/about/sustainable-techn...    False\n",
                            "1600  https://www.morningbrew.com/daily/stories/2020...    False\n",
                            "1712               https://www.ben-evans.com/newsletter     True\n",
                            "1562  https://theconversation.com/northern-irelands-...    False"
                        ]
                    },
                    "execution_count": 443,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df_raw.sample(10)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The database has only two variables of which ones is an object and it seems to be a string. The other variable is a boolean and it seems to be the target that classify the URL between spam and recular URL.\n",
                "\n",
                "Next i am going to change the data type of the target variable to facilitate the encoding."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 444,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_interim=df_raw.copy() # copy of df_raw to make the processing"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 445,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_interim['is_spam']=df_interim['is_spam'].astype('category')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Encoding**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 446,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_interim['is_spam']=df_interim['is_spam'].cat.codes"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 447,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>url</th>\n",
                            "      <th>is_spam</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>2140</th>\n",
                            "      <td>https://thehustle.co/06302020-Zwift-training/</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1049</th>\n",
                            "      <td>https://theneed2know.us2.list-manage.com/about</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1472</th>\n",
                            "      <td>https://austinkleon.com/newsletter/</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1092</th>\n",
                            "      <td>https://people.com/country/dixie-chicks-change...</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1772</th>\n",
                            "      <td>https://www.nbcnews.com/news/us-news/saharan-d...</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1617</th>\n",
                            "      <td>https://www.morningbrew.com/daily/r/</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>432</th>\n",
                            "      <td>https://apnews.com/4dcff8f062bae9e1fe3885c346b...</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1730</th>\n",
                            "      <td>https://thekanyestory.com/</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1039</th>\n",
                            "      <td>https://www.esquire.com/uk/culture/a32848474/v...</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2441</th>\n",
                            "      <td>https://www.densediscovery.com/issues/94#comments</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "                                                    url  is_spam\n",
                            "2140      https://thehustle.co/06302020-Zwift-training/        0\n",
                            "1049     https://theneed2know.us2.list-manage.com/about        1\n",
                            "1472                https://austinkleon.com/newsletter/        1\n",
                            "1092  https://people.com/country/dixie-chicks-change...        0\n",
                            "1772  https://www.nbcnews.com/news/us-news/saharan-d...        0\n",
                            "1617               https://www.morningbrew.com/daily/r/        1\n",
                            "432   https://apnews.com/4dcff8f062bae9e1fe3885c346b...        0\n",
                            "1730                         https://thekanyestory.com/        0\n",
                            "1039  https://www.esquire.com/uk/culture/a32848474/v...        0\n",
                            "2441  https://www.densediscovery.com/issues/94#comments        0"
                        ]
                    },
                    "execution_count": 447,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df_interim.sample(10)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Setep 2: Preprocess the data with NLP techniques**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 448,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "url        2369\n",
                            "is_spam       2\n",
                            "dtype: int64"
                        ]
                    },
                    "execution_count": 448,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df_interim.nunique()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "There is some dupliquetade url, so i delete it."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 449,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_interim.drop_duplicates(inplace=True)\n",
                "df_interim.reset_index(inplace=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 450,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "(2369, 3)"
                        ]
                    },
                    "execution_count": 450,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df_interim.shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 451,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>index</th>\n",
                            "      <th>url</th>\n",
                            "      <th>is_spam</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>1753</th>\n",
                            "      <td>2099</td>\n",
                            "      <td>https://thehustle.co/06292020-Amazon-vehicles/</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>469</th>\n",
                            "      <td>543</td>\n",
                            "      <td>https://apnews.com/4565b519d6b7d0a673105767148...</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>541</th>\n",
                            "      <td>642</td>\n",
                            "      <td>https://www.cbsnews.com/news/fauci-coronavirus...</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>756</th>\n",
                            "      <td>901</td>\n",
                            "      <td>https://www.theguardian.com/us-news/2020/jun/2...</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>944</th>\n",
                            "      <td>1129</td>\n",
                            "      <td>https://en.wikipedia.org/wiki/Zuihitsu</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1488</th>\n",
                            "      <td>1764</td>\n",
                            "      <td>https://cheddar.com/media/stocks-sink-coronavi...</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1622</th>\n",
                            "      <td>1945</td>\n",
                            "      <td>https://www.nytimes.com/2020/06/24/us/confeder...</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1799</th>\n",
                            "      <td>2158</td>\n",
                            "      <td>https://subscribe.washingtonpost.com/newslette...</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>561</th>\n",
                            "      <td>667</td>\n",
                            "      <td>https://www.morningbrew.com/daily/stories/2020...</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1016</th>\n",
                            "      <td>1207</td>\n",
                            "      <td>https://www.imperica.com/en/</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "      index                                                url  is_spam\n",
                            "1753   2099     https://thehustle.co/06292020-Amazon-vehicles/        0\n",
                            "469     543  https://apnews.com/4565b519d6b7d0a673105767148...        0\n",
                            "541     642  https://www.cbsnews.com/news/fauci-coronavirus...        0\n",
                            "756     901  https://www.theguardian.com/us-news/2020/jun/2...        0\n",
                            "944    1129             https://en.wikipedia.org/wiki/Zuihitsu        0\n",
                            "1488   1764  https://cheddar.com/media/stocks-sink-coronavi...        0\n",
                            "1622   1945  https://www.nytimes.com/2020/06/24/us/confeder...        0\n",
                            "1799   2158  https://subscribe.washingtonpost.com/newslette...        1\n",
                            "561     667  https://www.morningbrew.com/daily/stories/2020...        0\n",
                            "1016   1207                       https://www.imperica.com/en/        1"
                        ]
                    },
                    "execution_count": 451,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df_interim.sample(10)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Some things i can detect at plain sight:\n",
                "\n",
                "- strange symbols that has been remove\n",
                "\n",
                "- the '-' seems to separate words on the url\n",
                "\n",
                "- https and www have to be remove"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 452,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_interim['url'] = df_interim['url'].str.replace(r'-', ' ', regex=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 453,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_interim['url']=df_interim['url'].str.strip() # delet the firt and last space\n",
                "df_interim['url']=df_interim['url'].str.lower() # change all the text to lower\n",
                "# clean up strange symbols and standardize \n",
                "df_interim[\"url\"] = df_interim[\"url\"].apply(lambda x: re.sub(r'www',\" \",x))\n",
                "df_interim['url'] = df_interim['url'].str.replace('''[?&#,;ü_=%./']''','',regex=True)\n",
                "df_interim['url'] = df_interim['url'].str.replace(r'http(s):', '', regex=True)\n",
                "df_interim['url'] = df_interim['url'].str.replace(r'http:', '', regex=True)\n",
                "df_interim['url'] = df_interim['url'].str.replace(r'com', '', regex=True)\n",
                "# remove all numbers\n",
                "df_interim['url'] = df_interim['url'].str.replace(r'[\\d-]', '', regex=True) \n",
                "# remove all single letters\n",
                "df_interim[\"url\"] = df_interim[\"url\"].apply(lambda x: re.sub(r'\\b[a-zA-Z]\\b',\" \",x))\n",
                "# remove characters repited more than two times\n",
                "df_interim['url']=df_interim['url'].str.replace(r'([a-zA-Z])\\1{2,}',r'\\1',regex=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 454,
            "metadata": {},
            "outputs": [],
            "source": [
                "# remove stopwords\n",
                "stop=stopwords.words('english')\n",
                "\n",
                "def remove_stopwords(message):\n",
                "    if message is not None:\n",
                "        words = message.strip().split()\n",
                "        words_filtered = []\n",
                "        for word in words:\n",
                "            if word not in stop:\n",
                "                words_filtered.append(word)\n",
                "                result = \" \".join(words_filtered)\n",
                "    else:\n",
                "        result = None\n",
                "\n",
                "    return result"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 455,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_interim['url']=df_interim['url'].apply(remove_stopwords)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "To control I display first 60 words separately to see if they were cleaned up."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 456,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "coronavirus                                    107\n",
                            "new                                             62\n",
                            "reutersarticleus                                59\n",
                            "trump                                           54\n",
                            "covid                                           51\n",
                            "us                                              50\n",
                            "sunday                                          45\n",
                            "numlocksubstackpnumlock                         42\n",
                            "court                                           38\n",
                            "cases                                           31\n",
                            "police                                          29\n",
                            "black                                           27\n",
                            "facebook                                        27\n",
                            "pandemic                                        25\n",
                            "world                                           23\n",
                            "says                                            23\n",
                            "usa                                             21\n",
                            "live                                            21\n",
                            "year                                            20\n",
                            "york                                            20\n",
                            "million                                         19\n",
                            "health                                          19\n",
                            "home                                            19\n",
                            "supreme                                         18\n",
                            "mask                                            18\n",
                            "first                                           18\n",
                            "face                                            18\n",
                            "change                                          17\n",
                            "law                                             17\n",
                            "history                                         16\n",
                            "boycott                                         16\n",
                            "america                                         16\n",
                            "people                                          16\n",
                            "reopening                                       16\n",
                            "billion                                         15\n",
                            "lives                                           15\n",
                            "economy                                         15\n",
                            "state                                           15\n",
                            "next                                            14\n",
                            "masks                                           14\n",
                            "thehustleco                                     14\n",
                            "climate                                         14\n",
                            "open                                            14\n",
                            "ad                                              14\n",
                            "china                                           14\n",
                            "emailcampaigncopyutmmediumemailutmtermfbeaa     14\n",
                            "matter                                          14\n",
                            "one                                             14\n",
                            "vote                                            13\n",
                            "states                                          13\n",
                            "social                                          13\n",
                            "protest                                         13\n",
                            "briefingdaynmmentform                           13\n",
                            "protests                                        13\n",
                            "ea                                              12\n",
                            "set                                             12\n",
                            "north                                           12\n",
                            "back                                            12\n",
                            "abortion                                        12\n",
                            "house                                           12\n",
                            "dtype: int64"
                        ]
                    },
                    "execution_count": 456,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df_interim['url'].str.split(expand=True).stack().value_counts()[:60]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 457,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>index</th>\n",
                            "      <th>url</th>\n",
                            "      <th>is_spam</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>956</th>\n",
                            "      <td>1142</td>\n",
                            "      <td>youtubewatchvrivqdzhq</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2040</th>\n",
                            "      <td>2467</td>\n",
                            "      <td>docsgoogledocumentdykvrkybxbuvkkn yedxxosnaqwd...</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1050</th>\n",
                            "      <td>1250</td>\n",
                            "      <td>insidehookarticlepoliticsedgy edy lazy joe rog...</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>716</th>\n",
                            "      <td>851</td>\n",
                            "      <td>latimescaliforniastory george floyd carotid ne...</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>575</th>\n",
                            "      <td>686</td>\n",
                            "      <td>lunyacocollectionshey skimmrs heres use code s...</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2131</th>\n",
                            "      <td>2695</td>\n",
                            "      <td>ewtvcurb enthusiasm renewed season</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1341</th>\n",
                            "      <td>1593</td>\n",
                            "      <td>cnbcamazon buys self driving technology pany z...</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1242</th>\n",
                            "      <td>1472</td>\n",
                            "      <td>austinkleonnewsletter</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2061</th>\n",
                            "      <td>2602</td>\n",
                            "      <td>morningbrewdaily</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1905</th>\n",
                            "      <td>2295</td>\n",
                            "      <td>theskimmpicks hottest books season ofbwmpvfwyw...</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "      index                                                url  is_spam\n",
                            "956    1142                              youtubewatchvrivqdzhq        0\n",
                            "2040   2467  docsgoogledocumentdykvrkybxbuvkkn yedxxosnaqwd...        1\n",
                            "1050   1250  insidehookarticlepoliticsedgy edy lazy joe rog...        0\n",
                            "716     851  latimescaliforniastory george floyd carotid ne...        0\n",
                            "575     686  lunyacocollectionshey skimmrs heres use code s...        0\n",
                            "2131   2695                 ewtvcurb enthusiasm renewed season        0\n",
                            "1341   1593  cnbcamazon buys self driving technology pany z...        0\n",
                            "1242   1472                              austinkleonnewsletter        1\n",
                            "2061   2602                                   morningbrewdaily        0\n",
                            "1905   2295  theskimmpicks hottest books season ofbwmpvfwyw...        1"
                        ]
                    },
                    "execution_count": 457,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df_interim.sample(10)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "It seems that some url don't has space between different words, so it would be dificult for the algorithm to learn from it. Therefore, it is necessary to apply word segmentation.\n",
                "\n",
                "I am going to apply an algorithm that I have found in: https://grantjenks.com/docs/wordsegment/#:~:text=WordSegment%20is%20an%20Apache2%20licensed,Segaran%20and%20Hammerbacher%2C%202009)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 458,
            "metadata": {},
            "outputs": [],
            "source": [
                "load() # reads and parses the unigrams and bigrams data from disk"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 459,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Function that makes words segmentarion to each row\n",
                "def segment_words(message):\n",
                "    if message is not None:\n",
                "        words = segment(message)\n",
                "        words_filtered = []\n",
                "        for word in words:\n",
                "            if word not in stop: # if any word is in stopwords, it removes\n",
                "                words_filtered.append(word)\n",
                "                result = \" \".join(words_filtered)\n",
                "    else:\n",
                "        result = None\n",
                "\n",
                "    return result"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 460,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_interim['url']=df_interim['url'].apply(segment_words)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 461,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>index</th>\n",
                            "      <th>url</th>\n",
                            "      <th>is_spam</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>443</th>\n",
                            "      <td>514</td>\n",
                            "      <td>verge microsoft gaming cloud xbox future</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2238</th>\n",
                            "      <td>2828</td>\n",
                            "      <td>numlock sub stack p numlock sunday olga khaz w...</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1156</th>\n",
                            "      <td>1383</td>\n",
                            "      <td>wordpress creative mornings</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1058</th>\n",
                            "      <td>1259</td>\n",
                            "      <td>story california sunday eleanor davis hugs loo...</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2349</th>\n",
                            "      <td>2977</td>\n",
                            "      <td>venture beat ibm uses enhance old wimbledon te...</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>397</th>\n",
                            "      <td>445</td>\n",
                            "      <td>cnn tech wire card missing money index html</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>879</th>\n",
                            "      <td>1054</td>\n",
                            "      <td>week articles seattle police free autonomous z...</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>436</th>\n",
                            "      <td>507</td>\n",
                            "      <td>us four sigma tic summer sale</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>720</th>\n",
                            "      <td>856</td>\n",
                            "      <td>cnet news chicken run sequel ing netflix</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>411</th>\n",
                            "      <td>466</td>\n",
                            "      <td>chocolate basil squarespace blog pretzel short...</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "      index                                                url  is_spam\n",
                            "443     514           verge microsoft gaming cloud xbox future        0\n",
                            "2238   2828  numlock sub stack p numlock sunday olga khaz w...        1\n",
                            "1156   1383                        wordpress creative mornings        1\n",
                            "1058   1259  story california sunday eleanor davis hugs loo...        0\n",
                            "2349   2977  venture beat ibm uses enhance old wimbledon te...        0\n",
                            "397     445        cnn tech wire card missing money index html        0\n",
                            "879    1054  week articles seattle police free autonomous z...        0\n",
                            "436     507                      us four sigma tic summer sale        0\n",
                            "720     856           cnet news chicken run sequel ing netflix        0\n",
                            "411     466  chocolate basil squarespace blog pretzel short...        0"
                        ]
                    },
                    "execution_count": 461,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df_interim.sample(10)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now that the url is cleaner, i select the target and feature variable and split the original sample between training and test sample."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 462,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_final=df_interim.copy()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 463,
            "metadata": {},
            "outputs": [],
            "source": [
                "y=df_final['is_spam']\n",
                "X=df_final['url']"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 464,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "0    0.897003\n",
                            "1    0.102997\n",
                            "Name: is_spam, dtype: float64"
                        ]
                    },
                    "execution_count": 464,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "y.value_counts(normalize=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The sample is unbalanced, this must be taken into account when applying the model."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 465,
            "metadata": {},
            "outputs": [],
            "source": [
                "X_train,X_test,y_train,y_test=train_test_split(X,y,random_state=2007,stratify=y)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Tokenization**\n",
                "\n",
                "Transform the body of text into a sparse matrix of numbers that the computer can pass to machine learning algorithms."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 466,
            "metadata": {},
            "outputs": [],
            "source": [
                "vec=CountVectorizer(stop_words='english')\n",
                "X_train=vec.fit_transform(X_train).toarray()\n",
                "X_test=vec.transform(X_test).toarray()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 467,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "(1776, 4720)"
                        ]
                    },
                    "execution_count": 467,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "X_train.shape"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We can see that there are 4720 columns that refers to the different unique words inside each url. Now we could see the first ten unique words."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 468,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "array(['aaae', 'aadac', 'aafc', 'aah', 'ab', 'abacus', 'abba', 'abbott',\n",
                            "       'abbreviated', 'abc'], dtype=object)"
                        ]
                    },
                    "execution_count": 468,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "vec.get_feature_names_out()[:10]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**SVM classifier**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 469,
            "metadata": {},
            "outputs": [],
            "source": [
                "clf_svm = svm.SVC(C=1.0, kernel='linear', degree=3,random_state=3107, gamma='auto',class_weight='balanced') "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 470,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Accuracy scores\n",
                        "              precision    recall  f1-score   support\n",
                        "\n",
                        "           0       0.96      0.92      0.94       532\n",
                        "           1       0.49      0.70      0.58        61\n",
                        "\n",
                        "    accuracy                           0.89       593\n",
                        "   macro avg       0.73      0.81      0.76       593\n",
                        "weighted avg       0.92      0.89      0.90       593\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "clf_svm.fit(X_train, y_train) \n",
                "y_pred = clf_svm.predict(X_test)\n",
                "print('Accuracy scores')\n",
                "print(classification_report(y_test, y_pred))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The accurancy of the model is 89% which is very good! Indeed the recall almost reach the 70% for the minority class."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Plus: Naive Bayes classifier**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 471,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "              precision    recall  f1-score   support\n",
                        "\n",
                        "           0       0.96      0.98      0.97       532\n",
                        "           1       0.75      0.62      0.68        61\n",
                        "\n",
                        "    accuracy                           0.94       593\n",
                        "   macro avg       0.85      0.80      0.82       593\n",
                        "weighted avg       0.94      0.94      0.94       593\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "nb=MultinomialNB()\n",
                "nb.fit(X_train,y_train)\n",
                "nb_y_pred=nb.predict(X_test)\n",
                "print(classification_report(y_test,nb_y_pred))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Among both classifiers, SVM algorithm has better recall ratio but worst accuracy than Naive Bayes"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 472,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pickle\n",
                "filename = '/workspace/NLP/models/finalized_model.sav'\n",
                "pickle.dump(clf_svm, open(filename, 'wb'))"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.8.13 64-bit ('3.8.13')",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.13"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "110cc1dee26208153f2972f08a2ad52b6a56238dc66d48e87fb757ef2996db56"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
